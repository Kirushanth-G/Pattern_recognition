{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 925, 'name': 'Infrared Thermography Temperature', 'repository_url': 'https://archive.ics.uci.edu/dataset/925/infrared+thermography+temperature+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/925/data.csv', 'abstract': 'The Infrared Thermography Temperature Dataset contains temperatures read from various locations of inferred images about patients, with the addition of oral temperatures measured for each individual. The 33 features consist of gender, age, ethnicity, ambiant temperature, humidity, distance, and other temperature readings from the thermal images. The dataset is intended to be used in a regression task to predict the oral temperature using the environment information as well as the thermal image readings. ', 'area': 'Health and Medicine', 'tasks': ['Regression'], 'characteristics': ['Tabular'], 'num_instances': 1020, 'num_features': 33, 'feature_types': ['Real', 'Categorical'], 'demographics': ['Gender', 'Age', 'Ethnicity'], 'target_col': ['aveOralF', 'aveOralM'], 'index_col': ['SubjectID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2021, 'last_updated': 'Tue Dec 12 2023', 'dataset_doi': '10.13026/9ay4-2c37', 'creators': ['Quanzeng Wang', 'Yangling Zhou', 'Pejman Ghassemi', 'David McBride', 'J. Casamento', 'T. Pfefer', 'Quanzeng Wang', 'Yangling Zhou', 'Pejman Ghassemi', 'David McBride', 'J. Casamento', 'T. Pfefer'], 'intro_paper': {'title': 'Infrared Thermography for Measuring Elevated Body Temperature: Clinical Accuracy, Calibration, and Evaluation', 'authors': 'Quanzeng Wang, Yangling Zhou, Pejman Ghassemi, David McBride, J. Casamento, T. Pfefer', 'published_in': 'Italian National Conference on Sensors', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/443b9932d295ca3a014e7d874b4bd77a33a276bd', 'doi': None}, 'additional_info': {'summary': None, 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '- gender\\n- age\\n- ethnicity\\n- ambiant temperature\\n- humidity\\n- distance\\n- temperature readings from the thermal images', 'citation': None}, 'external_url': 'https://physionet.org/content/face-oral-temp-data/1.0.0/'}\n",
      "           name     role         type demographic  \\\n",
      "0     SubjectID       ID  Categorical        None   \n",
      "1      aveOralF   Target   Continuous        None   \n",
      "2      aveOralM   Target   Continuous        None   \n",
      "3        Gender  Feature  Categorical      Gender   \n",
      "4           Age  Feature  Categorical         Age   \n",
      "5     Ethnicity  Feature  Categorical   Ethnicity   \n",
      "6         T_atm  Feature   Continuous        None   \n",
      "7      Humidity  Feature   Continuous        None   \n",
      "8      Distance  Feature   Continuous        None   \n",
      "9     T_offset1  Feature   Continuous        None   \n",
      "10    Max1R13_1  Feature   Continuous        None   \n",
      "11    Max1L13_1  Feature   Continuous        None   \n",
      "12  aveAllR13_1  Feature   Continuous        None   \n",
      "13  aveAllL13_1  Feature   Continuous        None   \n",
      "14        T_RC1  Feature   Continuous        None   \n",
      "15    T_RC_Dry1  Feature   Continuous        None   \n",
      "16    T_RC_Wet1  Feature   Continuous        None   \n",
      "17    T_RC_Max1  Feature   Continuous        None   \n",
      "18        T_LC1  Feature   Continuous        None   \n",
      "19    T_LC_Dry1  Feature   Continuous        None   \n",
      "20    T_LC_Wet1  Feature   Continuous        None   \n",
      "21    T_LC_Max1  Feature   Continuous        None   \n",
      "22         RCC1  Feature   Continuous        None   \n",
      "23         LCC1  Feature   Continuous        None   \n",
      "24   canthiMax1  Feature   Continuous        None   \n",
      "25  canthi4Max1  Feature   Continuous        None   \n",
      "26      T_FHCC1  Feature   Continuous        None   \n",
      "27      T_FHRC1  Feature   Continuous        None   \n",
      "28      T_FHLC1  Feature   Continuous        None   \n",
      "29      T_FHBC1  Feature   Continuous        None   \n",
      "30      T_FHTC1  Feature   Continuous        None   \n",
      "31    T_FH_Max1  Feature   Continuous        None   \n",
      "32   T_FHC_Max1  Feature   Continuous        None   \n",
      "33       T_Max1  Feature   Continuous        None   \n",
      "34        T_OR1  Feature   Continuous        None   \n",
      "35    T_OR_Max1  Feature   Continuous        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                          Subject ID  None             no  \n",
      "1              Oral temperature measured in fast mode  None             no  \n",
      "2           Oral temperature measured in monitor mode  None             no  \n",
      "3                                      Male or Female  None             no  \n",
      "4                          Age ranges in categories\\n  None             no  \n",
      "5   American Indian or Alaska Native, Asian, Black...  None             no  \n",
      "6                                 Ambiant temperature  None             no  \n",
      "7                                   Relative humidity  None             no  \n",
      "8       Distance between the subjects and the IRTs.    None             no  \n",
      "9   Temperature difference between the set and mea...  None             no  \n",
      "10  Max value of a circle with diameter of 13 pixe...  None             no  \n",
      "11  Max value of a circle with diameter of 13 pixe...  None             no  \n",
      "12  Average value of a circle with diameter of 13 ...  None             no  \n",
      "13  Average value of a circle with diameter of 13 ...  None             no  \n",
      "14  Average temperature of the highest four pixels...  None             no  \n",
      "15  Average temperature of the highest four pixels...  None             no  \n",
      "16  Average temperature of the highest four pixels...  None             no  \n",
      "17  Max value of a square of 24x24 pixels around t...  None             no  \n",
      "18  Average temperature of the highest four pixels...  None             no  \n",
      "19  Average temperature of the highest four pixels...  None             no  \n",
      "20  Average temperature of the highest four pixels...  None             no  \n",
      "21  Max value of a circle with diameter of 13 pixe...  None             no  \n",
      "22  Average value of a square of 3x3 pixels center...  None             no  \n",
      "23  Average value of a square of 3x3 pixels center...  None             no  \n",
      "24              Max value in the extended canthi area  None             no  \n",
      "25  Average temperature of the highest four pixels...  None             no  \n",
      "26  Average value in the center point of forehead,...  None             no  \n",
      "27  Average value in the right point of the forehe...  None             no  \n",
      "28  Average value in the left point of the forehea...  None             no  \n",
      "29  Average value in the bottom point of the foreh...  None             no  \n",
      "30  Average value in the top point of the forehead...  None             no  \n",
      "31  Maximum temperature within the extended forehe...  None             no  \n",
      "32  Max value in the center point of forehead, a s...  None             no  \n",
      "33  Maximum temperature within the whole face region.  None             no  \n",
      "34  Average temperature of the highest four pixels...  None             no  \n",
      "35       Maximum temperature within the mouth region.  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "infrared_thermography_temperature = fetch_ucirepo(id=925)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = infrared_thermography_temperature.data.features\n",
    "y = infrared_thermography_temperature.data.targets\n",
    "\n",
    "# metadata\n",
    "print(infrared_thermography_temperature.metadata)\n",
    "\n",
    "# variable information\n",
    "print(infrared_thermography_temperature.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender    Age                  Ethnicity  T_atm  Humidity  Distance  \\\n",
      "0    Male  41-50                      White   24.0      28.0       0.8   \n",
      "1  Female  31-40  Black or African-American   24.0      26.0       0.8   \n",
      "2  Female  21-30                      White   24.0      26.0       0.8   \n",
      "3  Female  21-30  Black or African-American   24.0      27.0       0.8   \n",
      "4    Male  18-20                      White   24.0      27.0       0.8   \n",
      "\n",
      "   T_offset1  Max1R13_1  Max1L13_1  aveAllR13_1  ...  T_FHCC1  T_FHRC1  \\\n",
      "0     0.7025    35.0300    35.3775      34.4000  ...  33.5775  33.4775   \n",
      "1     0.7800    34.5500    34.5200      33.9300  ...  34.0325  34.0550   \n",
      "2     0.8625    35.6525    35.5175      34.2775  ...  34.9000  34.8275   \n",
      "3     0.9300    35.2225    35.6125      34.3850  ...  34.4400  34.4225   \n",
      "4     0.8950    35.5450    35.6650      34.9100  ...  35.0900  35.1600   \n",
      "\n",
      "   T_FHLC1  T_FHBC1  T_FHTC1  T_FH_Max1  T_FHC_Max1   T_Max1    T_OR1  \\\n",
      "0  33.3725  33.4925  33.0025    34.5300     34.0075  35.6925  35.6350   \n",
      "1  33.6775  33.9700  34.0025    34.6825     34.6600  35.1750  35.0925   \n",
      "2  34.6475  34.8200  34.6700    35.3450     35.2225  35.9125  35.8600   \n",
      "3  34.6550  34.3025  34.9175    35.6025     35.3150  35.7200  34.9650   \n",
      "4  34.3975  34.6700  33.8275    35.4175     35.3725  35.8950  35.5875   \n",
      "\n",
      "   T_OR_Max1  \n",
      "0    35.6525  \n",
      "1    35.1075  \n",
      "2    35.8850  \n",
      "3    34.9825  \n",
      "4    35.6175  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "   aveOralF  aveOralM\n",
      "0     36.85     36.59\n",
      "1     37.00     37.19\n",
      "2     37.20     37.34\n",
      "3     36.85     37.09\n",
      "4     36.80     37.04\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Independent Variables: 33\n",
      "Number of Dependent Variables: 2\n"
     ]
    }
   ],
   "source": [
    "# Number of independent variables\n",
    "num_independent_vars = X.shape[1]\n",
    "\n",
    "# Number of dependent variables\n",
    "num_dependent_vars = y.shape[1]\n",
    "\n",
    "print(f'Number of Independent Variables: {num_independent_vars}')\n",
    "print(f'Number of Dependent Variables: {num_dependent_vars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Counts of missing values in each column:\n",
      "Gender         0\n",
      "Age            0\n",
      "Ethnicity      0\n",
      "T_atm          0\n",
      "Humidity       0\n",
      "Distance       2\n",
      "T_offset1      0\n",
      "Max1R13_1      0\n",
      "Max1L13_1      0\n",
      "aveAllR13_1    0\n",
      "aveAllL13_1    0\n",
      "T_RC1          0\n",
      "T_RC_Dry1      0\n",
      "T_RC_Wet1      0\n",
      "T_RC_Max1      0\n",
      "T_LC1          0\n",
      "T_LC_Dry1      0\n",
      "T_LC_Wet1      0\n",
      "T_LC_Max1      0\n",
      "RCC1           0\n",
      "LCC1           0\n",
      "canthiMax1     0\n",
      "canthi4Max1    0\n",
      "T_FHCC1        0\n",
      "T_FHRC1        0\n",
      "T_FHLC1        0\n",
      "T_FHBC1        0\n",
      "T_FHTC1        0\n",
      "T_FH_Max1      0\n",
      "T_FHC_Max1     0\n",
      "T_Max1         0\n",
      "T_OR1          0\n",
      "T_OR_Max1      0\n",
      "dtype: int64\n",
      "aveOralF    0\n",
      "aveOralM    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_counts_X = X.isnull().sum()\n",
    "missing_counts_y = y.isnull().sum()\n",
    "\n",
    "\n",
    "# Display the counts of missing values in each column\n",
    "print(\"\\nCounts of missing values in each column:\")\n",
    "print(missing_counts_X)\n",
    "print(missing_counts_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender         0\n",
      "Age            0\n",
      "Ethnicity      0\n",
      "T_atm          0\n",
      "Humidity       0\n",
      "Distance       0\n",
      "T_offset1      0\n",
      "Max1R13_1      0\n",
      "Max1L13_1      0\n",
      "aveAllR13_1    0\n",
      "aveAllL13_1    0\n",
      "T_RC1          0\n",
      "T_RC_Dry1      0\n",
      "T_RC_Wet1      0\n",
      "T_RC_Max1      0\n",
      "T_LC1          0\n",
      "T_LC_Dry1      0\n",
      "T_LC_Wet1      0\n",
      "T_LC_Max1      0\n",
      "RCC1           0\n",
      "LCC1           0\n",
      "canthiMax1     0\n",
      "canthi4Max1    0\n",
      "T_FHCC1        0\n",
      "T_FHRC1        0\n",
      "T_FHLC1        0\n",
      "T_FHBC1        0\n",
      "T_FHTC1        0\n",
      "T_FH_Max1      0\n",
      "T_FHC_Max1     0\n",
      "T_Max1         0\n",
      "T_OR1          0\n",
      "T_OR_Max1      0\n",
      "dtype: int64\n",
      "aveOralF    0\n",
      "aveOralM    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Combine X and y into a single DataFrame\n",
    "data_combined = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "data_combined = data_combined.dropna()\n",
    "\n",
    "# Separate X and y after dropping missing values\n",
    "X = data_combined.iloc[:, :-2]  # All columns except the last two\n",
    "y = data_combined.iloc[:, -2:]  # The last two columns\n",
    "\n",
    "#checking with NaN elements still exist\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding using sklearn OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for Age_21-25: 0.0213\n",
      "Coefficient for Age_21-30: 0.1344\n",
      "Coefficient for Age_26-30: -0.1200\n",
      "Coefficient for Age_31-40: -0.0316\n",
      "Coefficient for Age_41-50: -0.1375\n",
      "Coefficient for Age_51-60: -0.3805\n",
      "Coefficient for Age_>60: 0.0132\n",
      "Coefficient for Distance: -0.3523\n",
      "Coefficient for Humidity: 0.0013\n",
      "Coefficient for T_atm: -0.0016\n",
      "Coefficient for T_offset1: 0.1939\n",
      "Intercept: 37.0677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Select dependent and independent features\n",
    "dependent_feature = 'aveOralM'\n",
    "independent_features = ['Age', 'Distance', 'Humidity', 'T_atm', 'T_offset1'] \n",
    "# Extract the relevant columns\n",
    "X_selected = X[independent_features]\n",
    "y_selected = y[dependent_feature]\n",
    "\n",
    "# One-hot encode the \"Age\" feature\n",
    "# Keep other numerical features as is, and concatenate with the encoded \"Age\"\n",
    "cat_encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_encoded_age = cat_encoder.fit_transform(X_selected[['Age']])\n",
    "X_remaining_features = X_selected.drop(columns=['Age'])\n",
    "\n",
    "# Combine the one-hot encoded \"Age\" with the other features\n",
    "X_final = pd.concat([pd.DataFrame(X_encoded_age, columns=cat_encoder.get_feature_names_out(['Age'])), \n",
    "                     X_remaining_features.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_selected, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Estimate the coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# List the estimated coefficients with 4 decimal points\n",
    "for feature, coef in zip(X_final.columns, coefficients):\n",
    "    print(f'Coefficient for {feature}: {coef:.4f}')\n",
    "\n",
    "# Print the intercept with 4 decimal points\n",
    "intercept = model.intercept_\n",
    "print(f'Intercept: {intercept:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding using pandas pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for Distance: -0.3523080919385941\n",
      "Coefficient for Humidity: 0.0012849527536311616\n",
      "Coefficient for T_atm: -0.0015667543247122708\n",
      "Coefficient for T_offset1: 0.19385383302856599\n",
      "Coefficient for Age_21-25: 0.02134420060099466\n",
      "Coefficient for Age_21-30: 0.13439604794404944\n",
      "Coefficient for Age_26-30: -0.120031553987434\n",
      "Coefficient for Age_31-40: -0.03160729518785476\n",
      "Coefficient for Age_41-50: -0.13745863944369677\n",
      "Coefficient for Age_51-60: -0.380531666333965\n",
      "Coefficient for Age_>60: 0.013202726708834649\n",
      "Intercept: 37.06774005940642\n"
     ]
    }
   ],
   "source": [
    "# Select dependent and independent features\n",
    "dependent_feature = 'aveOralM'\n",
    "independent_features = ['Age', 'Distance', 'Humidity', 'T_atm', 'T_offset1'] \n",
    "\n",
    "# Extract the relevant columns\n",
    "X_selected = X[independent_features]\n",
    "y_selected = y[dependent_feature]\n",
    "\n",
    "# One-hot encode the \"Age\" feature using pd.get_dummies\n",
    "X_final = pd.get_dummies(X_selected, columns=['Age'], drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_selected, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Estimate the coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# List the estimated coefficients\n",
    "for feature, coef in zip(X_final.columns, coefficients):\n",
    "    print(f'Coefficient for {feature}: {coef}')\n",
    "\n",
    "# Print the intercept\n",
    "intercept = model.intercept_\n",
    "print(f'Intercept: {intercept}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for T_OR1: 0.5034\n",
      "Coefficient for T_OR_Max1: 0.0217\n",
      "Coefficient for T_FHC_Max1: -0.0602\n",
      "Coefficient for T_FH_Max1: 0.3594\n",
      "Intercept: 7.6115\n"
     ]
    }
   ],
   "source": [
    "# Select independent features\n",
    "independent_features = ['T_OR1', 'T_OR_Max1', 'T_FHC_Max1', 'T_FH_Max1']\n",
    "\n",
    "# Extract the relevant columns\n",
    "X_selected = X[independent_features]\n",
    "y_selected = y['aveOralM']  \n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Estimate the coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# List the estimated coefficients\n",
    "for feature, coef in zip(independent_features, coefficients):\n",
    "    print(f'Coefficient for {feature}: {coef:.4f}')\n",
    "\n",
    "# Print the intercept\n",
    "intercept = model.intercept_\n",
    "print(f'Intercept: {intercept:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS: 75.0953\n",
      "RSE: 0.3047\n",
      "MSE: 0.0923\n",
      "R^2: 0.6429\n",
      "Standard Errors: \n",
      "const         0.793406\n",
      "T_OR1         0.859272\n",
      "T_OR_Max1     0.857762\n",
      "T_FHC_Max1    0.043671\n",
      "T_FH_Max1     0.048925\n",
      "dtype: float64\n",
      "t-statistics: \n",
      "const         9.593404\n",
      "T_OR1         0.585833\n",
      "T_OR_Max1     0.025287\n",
      "T_FHC_Max1   -1.379061\n",
      "T_FH_Max1     7.345249\n",
      "dtype: float64\n",
      "p-values: \n",
      "const         1.025961e-20\n",
      "T_OR1         5.581512e-01\n",
      "T_OR_Max1     9.798324e-01\n",
      "T_FHC_Max1    1.682570e-01\n",
      "T_FH_Max1     5.018475e-13\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#model predictions using training data\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate RSS\n",
    "RSS = np.sum((y_train - y_pred) ** 2)\n",
    "\n",
    "# Calculate RSE\n",
    "N = len(y_train)\n",
    "d = X_train.shape[1]\n",
    "RSE = np.sqrt(RSS / (N - d - 1))\n",
    "\n",
    "# Calculate MSE\n",
    "MSE = RSS / N\n",
    "\n",
    "# Calculate R^2\n",
    "TSS = np.sum((y_train - np.mean(y_train)) ** 2)\n",
    "R2 = 1 - (RSS / TSS)\n",
    "\n",
    "# Use statsmodels to get standard errors, t-statistics, and p-values\n",
    "X_train_sm = sm.add_constant(X_train) \n",
    "model_sm = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "# Standard errors\n",
    "std_errors = model_sm.bse\n",
    "\n",
    "# t-statistics\n",
    "t_values = model_sm.tvalues\n",
    "\n",
    "# p-values\n",
    "p_values = model_sm.pvalues\n",
    "\n",
    "# Print the results\n",
    "print(f\"RSS: {RSS:.4f}\")\n",
    "print(f\"RSE: {RSE:.4f}\")\n",
    "print(f\"MSE: {MSE:.4f}\")\n",
    "print(f\"R^2: {R2:.4f}\")\n",
    "print(f\"Standard Errors: \\n{std_errors}\")\n",
    "print(f\"t-statistics: \\n{t_values}\")\n",
    "print(f\"p-values: \\n{p_values}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
